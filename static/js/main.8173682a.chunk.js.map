{"version":3,"sources":["App.tsx","index.js"],"names":["App","useState","setPc","setSocket","localVideoRef","useRef","remoteVideoRef","pc_config","urls","useEffect","newSocket","io","connect","newPC","RTCPeerConnection","on","allUsers","length","createOffer","sdp","console","log","createAnswer","setRemoteDescription","RTCSessionDescription","candidate","addIceCandidate","RTCIceCandidate","then","navigator","mediaDevices","getUserMedia","video","audio","stream","current","srcObject","getTracks","forEach","track","addTrack","onicecandidate","e","emit","oniceconnectionstatechange","ontrack","ev","streams","room","email","catch","error","offerToReceiveAudio","offerToReceiveVideo","setLocalDescription","sdp1","style","width","height","margin","backgroundColor","muted","ref","autoPlay","id","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"6SA0JeA,EApJH,WAAO,IAAD,EACIC,qBADJ,mBACLC,GADK,aAEYD,qBAFZ,mBAEDE,GAFC,WAIZC,EAAgBC,iBAAyB,MACzCC,EAAiBD,iBAAyB,MAGxCE,EAAY,CAChB,WAAc,CAMZ,CACEC,KAAO,kCAuGb,OAjGAC,qBAAU,WAET,IAAIC,EAAYC,IAAGC,QAAQ,0BACtBC,EAAQ,IAAIC,kBAAkBP,GAGlCG,EAAUK,GAAG,aAAa,SAACC,GACfA,EAASC,OACT,GACRC,OAIJR,EAAUK,GAAG,YAAY,SAACI,GAExBC,QAAQC,IAAI,aACZC,EAAaH,MAGfT,EAAUK,GAAG,aAAa,SAACI,GACzBC,QAAQC,IAAI,cACZR,EAAMU,qBAAqB,IAAIC,sBAAsBL,OAIvDT,EAAUK,GAAG,gBAAgB,SAACU,GAC5BZ,EAAMa,gBAAgB,IAAIC,gBAAgBF,IAAYG,MAAK,WACzDR,QAAQC,IAAI,+BAIhBlB,EAAUO,GACVR,EAAMW,GAENgB,UAAUC,aAAaC,aAAa,CAClCC,OAAO,EACPC,OAAO,IACNL,MAAK,SAAAM,GACF9B,EAAc+B,UAAS/B,EAAc+B,QAAQC,UAAYF,GAE7DA,EAAOG,YAAYC,SAAQ,SAAAC,GACzB1B,EAAM2B,SAASD,EAAOL,MAExBrB,EAAM4B,eAAiB,SAACC,GAClBA,EAAEjB,YACJL,QAAQC,IAAI,kBACZX,EAAUiC,KAAK,YAAaD,EAAEjB,aAGlCZ,EAAM+B,2BAA6B,SAACF,GAClCtB,QAAQC,IAAIqB,IAGd7B,EAAMgC,QAAU,SAACC,GACf1B,QAAQC,IAAI,2BACTf,EAAe6B,UAAS7B,EAAe6B,QAAQC,UAAYU,EAAGC,QAAQ,KAG3ErC,EAAUiC,KAAK,YAAa,CAACK,KAAM,OAAQC,MAAO,wBAEjDC,OAAM,SAAAC,GACP/B,QAAQC,IAAR,8BAAmC8B,OAIvC,IAAMjC,EAAc,WAClBE,QAAQC,IAAI,gBACZR,EAAMK,YAAY,CAACkC,qBAAqB,EAAMC,qBAAqB,IAChEzB,MAAK,SAAAT,GACJN,EAAMyC,oBAAoB,IAAI9B,sBAAsBL,IACpDT,EAAUiC,KAAK,QAASxB,MAEzB+B,OAAM,SAAAC,GACL/B,QAAQC,IAAI8B,OAIV7B,EAAe,SAACH,GAClBN,EAAMU,qBAAqB,IAAIC,sBAAsBL,IAAMS,MAAK,WAC9DR,QAAQC,IAAI,yCACZR,EAAMS,aAAa,CAAC+B,qBAAqB,EAAMD,qBAAqB,IACnExB,MAAK,SAAA2B,GAELnC,QAAQC,IAAI,iBACXR,EAAMyC,oBAAoB,IAAI9B,sBAAsB+B,IACpD7C,EAAUiC,KAAK,SAAUY,MAE1BL,OAAM,SAAAC,GACL/B,QAAQC,IAAI8B,YAMnB,IAID,6BACI,2BACEK,MAAO,CACLC,MAAO,IACPC,OAAQ,IACRC,OAAQ,EACRC,gBAAiB,SAEnBC,OAAK,EACLC,IAAM1D,EACN2D,UAAQ,IAEV,2BACEC,GAAG,cACHR,MAAO,CACLC,MAAO,IACPC,OAAQ,IACRC,OAAQ,EACRC,gBAAiB,SAEnBE,IAAMxD,EACNyD,UAAQ,MC7IlBE,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,EAAD,OAEFC,SAASC,eAAe,W","file":"static/js/main.8173682a.chunk.js","sourcesContent":["import './App.css';\nimport React, {useState} from 'react';\nimport io from 'socket.io-client';\nimport {useRef} from 'react';\nimport {useEffect} from 'react';\n\nconst App = () => {\n  const [pc, setPc] = useState<RTCPeerConnection>(); // RTCPeerConnection\n  const [socket, setSocket] = useState<SocketIOClient.Socket>(); //singaling server와 통신할 socket\n\n  let localVideoRef = useRef<HTMLVideoElement>(null); //본인의 video, audio를 재생할 video 태그의 ref\n  let remoteVideoRef = useRef<HTMLVideoElement>(null); //상대방의 Video, autio를 재생할 video 태그의 ref\n\n  //RTCPeerConnection을 생성할 때의 Config\n  const pc_config = {\n    \"iceServers\": [\n      // {\n      //   urls: 'stun:3.34.249.175:3000'\n      //   // 'credentials': '[YOR CREDENTIALS]',\n      //   // 'username': '[USERNAME]'\n      // }\n      {\n        urls : 'stun:stun.l.google.com:19302'\n      }\n    ]\n  }\n\n  //socket 관련 이벤트 useEffect에 다 때려박음\n  useEffect(() => {\n    // let newSocket = io('https://rchatting.shop', {transports: ['websocket']});\n   let newSocket = io.connect('https://rchatting.shop');\n    let newPC = new RTCPeerConnection(pc_config);\n\n    //all_user :\n    newSocket.on('all_users', (allUsers: Array<{id: string, email: string}>) => {\n      let len = allUsers.length;\n      if (len > 0) {\n        createOffer();\n      }\n    });\n  \n    newSocket.on('getOffer', (sdp: RTCSessionDescription) => {\n      //console.log(sdp);\n      console.log('get offer');\n      createAnswer(sdp);\n    });\n  \n    newSocket.on('getAnswer', (sdp: RTCSessionDescription) => {\n      console.log('get answer');\n      newPC.setRemoteDescription(new RTCSessionDescription(sdp));\n      //console.log(sdp);\n    });\n  \n    newSocket.on('getCandidate', (candidate: RTCIceCandidateInit) => {\n      newPC.addIceCandidate(new RTCIceCandidate(candidate)).then(() => {\n        console.log('candidate add success');\n      })\n    })\n\n    setSocket(newSocket);\n    setPc(newPC);\n\n    navigator.mediaDevices.getUserMedia({\n      video: true,\n      audio: true\n    }).then(stream => {\n      if (localVideoRef.current) localVideoRef.current.srcObject = stream;\n\n      stream.getTracks().forEach(track => {\n        newPC.addTrack(track, stream);\n      })\n      newPC.onicecandidate = (e) => {\n        if (e.candidate) {\n          console.log('onicecandidate');\n          newSocket.emit('candidate', e.candidate);\n        }\n      }\n      newPC.oniceconnectionstatechange = (e) => {\n        console.log(e);\n      }\n      \n      newPC.ontrack = (ev) => {\n        console.log('add remotetrack success');\n        if(remoteVideoRef.current) remoteVideoRef.current.srcObject = ev.streams[0];\n      } \n\n      newSocket.emit('join_room', {room: '1234', email: 'sample@naver.com'});\n      \n    }).catch(error => {\n      console.log(`getUserMedia error: ${error}`);\n    });\n    \n\n  const createOffer = () => {\n    console.log('create offer');\n    newPC.createOffer({offerToReceiveAudio: true, offerToReceiveVideo: true})\n      .then(sdp => {\n        newPC.setLocalDescription(new RTCSessionDescription(sdp));\n        newSocket.emit('offer', sdp);\n      })\n      .catch(error => {\n        console.log(error);\n      })\n    }\n\n    const createAnswer = (sdp: RTCSessionDescription) => {\n        newPC.setRemoteDescription(new RTCSessionDescription(sdp)).then(() => {\n          console.log('answer set remote description success');\n          newPC.createAnswer({offerToReceiveVideo: true, offerToReceiveAudio: true})\n          .then(sdp1 => {\n            \n           console.log('create answer');\n            newPC.setLocalDescription(new RTCSessionDescription(sdp1));\n            newSocket.emit('answer', sdp1);\n          })\n          .catch(error => {\n            console.log(error);\n          })\n        })\n      \n    }\n\n  }, []);\n\n  // 본인과 상대방의 video 렌더링\n  return (\n    <div>\n        <video\n          style={{\n            width: 240,\n            height: 240,\n            margin: 5,\n            backgroundColor: 'black'\n          }}\n          muted\n          ref={ localVideoRef }\n          autoPlay>\n        </video>\n        <video\n          id='remotevideo'\n          style={{\n            width: 240,\n            height: 240,\n            margin: 5,\n            backgroundColor: 'black'\n          }}\n          ref={ remoteVideoRef }\n          autoPlay>\n        </video>\n      </div>\n  );\n}\n\n\nexport default App;\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"./index.css\";\nimport App from \"./App\";\n// import reportWebVitals from \"./reportWebVitals\";\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\n// reportWebVitals();\n"],"sourceRoot":""}